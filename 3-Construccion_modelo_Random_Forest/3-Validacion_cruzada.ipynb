{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde3dab5",
   "metadata": {},
   "source": [
    "# Usando la validacion cruzada\n",
    "\n",
    "En el notebook anterior, construimos un modelo de Bosques Aleatorios y realizamos una búsqueda manual de los hiperparámetros óptimos, como el número de árboles y la profundidad máxima. Si bien este enfoque nos dio un modelo con un sólido rendimiento del 82%, es crucial validar nuestros hallazgos de una manera más robusta.\n",
    "\n",
    "En este notebook, llevaremos la optimización de nuestro modelo al siguiente nivel. Utilizaremos validación cruzada junto con GridSearchCV para encontrar la combinación de hiperparámetros que garantice el mejor rendimiento de manera sistemática y confiable.\n",
    "\n",
    "El objetivo es confirmar si los valores que elegimos manualmente eran de hecho los óptimos y, al mismo tiempo, obtener un resultado que minimice el riesgo de sobreajuste al probar el modelo en múltiples divisiones de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1952c4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Mejores parámetros encontrados:\n",
      "{'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 170}\n",
      "\n",
      "Mejor F1-Score (promedio de 5-fold CV): 0.8147\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Cargamos el dataset y separamos los datos\n",
    "df_model_wine = pd.read_csv(\"dataset/wine_ready.csv\")\n",
    "X = df_model_wine.drop('quality_binary', axis=1)\n",
    "y = df_model_wine['quality_binary']\n",
    "\n",
    "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Definimos el modelo base\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definimos la \"rejilla\" de parámetros a probar\n",
    "# Incluimos los rangos alrededor de los valores óptimos que ya encontraste\n",
    "param_grid = {\n",
    "    'n_estimators': [160, 170, 180],\n",
    "    'max_depth': [18, 19, 20],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']  # Nuevo parámetro a probar\n",
    "}\n",
    "\n",
    "# Creamos el objeto GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',  # Usamos el f1-score como métrica\n",
    "    cv=5,                  # Usamos 5-fold cross-validation\n",
    "    n_jobs=-1,             # Usa todos los procesadores disponibles\n",
    "    verbose=1              # Muestra el progreso\n",
    ")\n",
    "\n",
    "# Ejecutamos la búsqueda exhaustiva\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimimos los mejores parámetros y el mejor score\n",
    "print(\"Mejores parámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"\\nMejor F1-Score (promedio de 5-fold CV): {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfc482e",
   "metadata": {},
   "source": [
    "#### Conclusiones\n",
    "\n",
    "Hemos completado la fase de optimización de nuestro modelo de Bosques Aleatorios utilizando la validación cruzada. La búsqueda exhaustiva de GridSearchCV ha arrojado la siguiente combinación de parámetros como la más óptima para nuestro conjunto de datos:\n",
    "\n",
    "1. n_estimators: 170\n",
    "\n",
    "2. max_depth: 20\n",
    "\n",
    "3. min_samples_leaf: 1\n",
    "\n",
    "4. max_features: sqrt\n",
    "\n",
    "El resultado final, con un F1-Score promedio de 0.8147, confirma que los parámetros encontrados en la búsqueda manual eran extraordinariamente cercanos a los verdaderos valores óptimos. Este hallazgo valida la solidez de nuestro análisis exploratorio y la metodología de optimización.\n",
    "\n",
    "Ahora tenemos un modelo final, cuyos hiperparámetros no han sido elegidos al azar, sino que han sido validados rigurosamente. Este modelo es robusto, confiable y está listo para ser utilizado para la predicción de nuevos datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
