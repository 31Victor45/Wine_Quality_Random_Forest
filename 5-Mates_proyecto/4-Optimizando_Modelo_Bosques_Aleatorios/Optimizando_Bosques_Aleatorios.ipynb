{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ac0a57",
   "metadata": {},
   "source": [
    "### 5. Optimización de Hiperparámetros (para mejorar el modelo)\n",
    "\n",
    "Los hiperparámetros son configuraciones externas al modelo que no se aprenden de los datos. Piénsalos como los \"controles\" o \"dial\" que ajustas para optimizar el rendimiento de tu modelo. Elegir la combinación correcta de hiperparámetros es crucial para evitar el sobreajuste y maximizar la precisión.\n",
    "\n",
    "#### Hiperparámetros Clave\n",
    "\n",
    "* **`n_estimators`:** Es el número de árboles que se construirán en el bosque. Generalmente, un número mayor de árboles mejora la precisión, pero también aumenta el tiempo de entrenamiento y el costo computacional.\n",
    "* **`max_depth`:** Define la profundidad máxima que puede tener cada árbol. Controla la complejidad del modelo. Si es muy grande, el árbol puede sobreajustarse a los datos de entrenamiento.\n",
    "* **`min_samples_leaf`:** Es el número mínimo de datos que debe haber en un nodo hoja. Este parámetro ayuda a controlar el tamaño de los árboles y evita que se ajusten a valores atípicos. Un valor más alto hace que el modelo sea más general.\n",
    "* **`max_features`:** Es el número de características que cada árbol considerará al tomar una decisión en cada división de nodo. Este es un parámetro clave para la \"aleatoriedad\" del algoritmo y ayuda a prevenir el sobreajuste.\n",
    "\n",
    "#### Búsqueda de Hiperparámetros\n",
    "\n",
    "En lugar de ajustar manualmente cada parámetro, se utilizan técnicas automatizadas para encontrar la combinación óptima.\n",
    "\n",
    "* **Grid Search (Búsqueda de Cuadrícula):** Es una técnica que evalúa exhaustivamente todas las posibles combinaciones de hiperparámetros que le proporcionas. Funciona creando una \"rejilla\" con todos los valores que quieres probar para cada parámetro y luego entrena un modelo para cada combinación.\n",
    "* **Cross-Validation (Validación Cruzada):** Este es el método que se utiliza para evaluar de manera robusta cada una de las combinaciones del `Grid Search`. En lugar de dividir los datos en un solo conjunto de entrenamiento y prueba, la validación cruzada divide los datos en \"pliegues\" (folds), entrena el modelo en algunos pliegues y lo prueba en los pliegues restantes. Esto asegura que la evaluación del modelo no dependa de una sola partición de datos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
